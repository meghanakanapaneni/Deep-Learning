{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(3*200*180,2000 ),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(2000, 1000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1000, 200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200, 100),   \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(100, 200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200, 1000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1000, 2000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(2000, 3*200*180),\n",
    "            nn.Sigmoid(),       \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        print(\"-\"*100)\n",
    "        print(len(encoded[0]))\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_dir = 'faces94' \n",
    "files = glob(f\"{root_dir}/**/**/**/*.jpg\")\n",
    "\n",
    "c2i = {\n",
    "    \"female\": 0,\n",
    "    \"male\":1,\n",
    "    \"malestaff\": 2 \n",
    "}\n",
    "\n",
    "c_files = files[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "transform_loader = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5],[0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "all_imgs = torch.stack([transform_loader(Image.open(x)) for x in c_files])\n",
    "all_label = torch.tensor([c2i[x.split('\\\\')[-3]] for x in c_files])\n",
    "\n",
    "train_idx, test_idx = train_test_split(range(len(all_imgs)), test_size=0.2, random_state=102)\n",
    "\n",
    "train_img = all_imgs[train_idx]\n",
    "train_label = all_label[train_idx]\n",
    "\n",
    "test_img = all_imgs[test_idx]\n",
    "test_label = all_label[test_idx]\n",
    "\n",
    "\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.005         \n",
    "DOWNLOAD_MNIST = True\n",
    "N_TEST_IMG = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "100\n",
      "tensor([[ 2.0602e-02, -7.9836e-02,  1.8840e-02,  1.0719e-01, -1.7152e-02,\n",
      "         -8.3083e-02,  3.2845e-02, -1.3921e-01,  3.3041e-02,  6.9663e-02,\n",
      "         -3.0524e-02,  2.8641e-02,  8.7731e-02, -5.3914e-02,  3.1062e-02,\n",
      "         -7.9491e-03, -6.2171e-02,  7.5188e-02, -7.5636e-03, -1.2576e-01,\n",
      "          8.4847e-02, -6.6230e-02, -3.4097e-02,  1.1698e-01, -1.4058e-02,\n",
      "          9.2134e-04,  9.3304e-02,  3.0077e-02,  7.0536e-02, -4.3180e-02,\n",
      "          7.9889e-05,  2.3725e-02, -4.9694e-02, -1.2361e-02, -1.1389e-01,\n",
      "          4.9921e-03,  3.9231e-02, -5.0697e-02,  3.9146e-03, -3.4713e-02,\n",
      "          1.1569e-01, -1.6963e-02,  1.9433e-03,  4.0434e-02,  7.8282e-02,\n",
      "         -8.1527e-03, -5.9038e-02, -6.1727e-03,  6.1871e-02,  7.2813e-02,\n",
      "          2.1582e-02,  6.8640e-02, -3.3016e-03, -8.3042e-02, -3.9683e-02,\n",
      "          6.0496e-02, -8.8021e-02,  4.9300e-02,  6.8347e-02, -1.6637e-02,\n",
      "          4.9145e-02, -6.4724e-02, -5.1851e-02, -5.7001e-02, -7.4932e-02,\n",
      "         -1.0861e-01, -1.8510e-02,  6.6928e-02, -4.3477e-02, -7.9661e-02,\n",
      "         -7.2713e-02, -3.0996e-02, -2.3628e-02,  1.5827e-01,  2.0028e-02,\n",
      "         -1.1995e-01, -5.6967e-02,  9.9556e-02, -1.0220e-01,  3.7894e-02,\n",
      "         -8.9233e-02, -6.5198e-02,  1.6171e-01,  1.7011e-01,  9.5038e-02,\n",
      "          1.3673e-02, -1.7351e-02, -2.1286e-02,  9.6295e-02, -3.4470e-02,\n",
      "         -1.0875e-03, -1.4573e-01, -4.7398e-02, -5.5574e-02,  1.0451e-01,\n",
      "         -1.3776e-02,  5.9592e-02,  1.4088e-02,  1.0188e-01,  2.9960e-02]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Epoch:  0 | train loss: 1.2029\n",
      "----------------------------------------------------------------------------------------------------\n",
      "100\n",
      "tensor([[-0.1575,  0.1893,  0.6202, -0.3731,  0.2957,  0.4327,  0.8044,  0.2588,\n",
      "          0.3959,  0.3529,  0.4589,  0.0295,  0.2108,  0.4140,  0.1457,  0.2991,\n",
      "          0.1057, -0.2347, -0.1962, -0.6322, -0.2299,  0.4116,  0.0996, -0.5049,\n",
      "         -0.0381, -0.0153,  0.1400,  0.2548,  0.3951, -0.0829,  0.3863, -0.1244,\n",
      "          0.3505, -0.0932, -0.1361,  0.5382, -0.2625, -0.4320, -0.5121, -0.3168,\n",
      "         -0.5771,  0.5491, -0.6550, -0.3994, -0.6840,  0.0816,  0.3456,  0.6797,\n",
      "          0.2950, -0.0310, -0.1936, -0.0544,  0.6467, -0.1685, -0.2762,  0.5389,\n",
      "         -0.3762,  0.0356,  0.4908,  0.4994,  0.2248,  0.0374, -0.6007, -0.7356,\n",
      "         -0.1028, -0.5836,  0.0895,  0.6165,  0.1110, -0.5956, -0.0709,  0.7026,\n",
      "          0.3789,  0.0045,  0.0398,  0.3913, -0.3440,  0.5104,  0.1571,  0.1592,\n",
      "          0.3968, -0.2461, -0.4691, -0.3091, -0.1689, -0.2714,  0.2111, -0.0426,\n",
      "         -0.0984,  0.4763,  0.5797, -0.0057, -0.6062, -0.1667, -0.1880, -0.1220,\n",
      "         -0.0291,  0.8180, -0.3239,  0.2771]], grad_fn=<AddmmBackward>)\n",
      "Epoch:  1 | train loss: 1.1548\n",
      "----------------------------------------------------------------------------------------------------\n",
      "100\n",
      "tensor([[ 0.2113, -0.4906, -0.2473, -0.2722,  0.1589,  0.2082, -0.0085, -0.2845,\n",
      "         -0.0760,  0.1402,  0.3325,  0.7809,  0.0913,  0.5412,  0.3514, -0.0222,\n",
      "          0.0127,  0.3227, -0.3291, -0.2059,  0.2890, -0.4614, -0.7369,  0.4863,\n",
      "         -0.4404,  0.5642, -0.2253, -0.0906,  0.3168, -0.3467, -0.5761,  0.2715,\n",
      "         -0.9789, -0.2028, -0.3108,  0.2719,  0.1948,  0.0167,  0.3705, -0.3078,\n",
      "          0.9898,  0.0377, -0.2247,  0.7815,  0.1750, -0.6214,  0.3076, -0.7745,\n",
      "          0.6789,  1.1973,  0.4408,  0.1705, -0.4398, -0.0852,  0.2830, -0.1173,\n",
      "         -0.7443,  0.0502,  0.0278, -0.2915, -0.2566, -0.1865,  0.0461, -0.7792,\n",
      "         -0.7452,  0.0342, -0.5355,  1.0186,  0.1126,  0.2080, -0.0580, -0.2752,\n",
      "          0.1905,  0.6807, -0.5409, -0.4773, -0.6998,  0.3078, -0.2680, -0.0817,\n",
      "         -0.2333,  0.4401,  0.8143,  0.7520,  1.2246,  0.0913,  0.3594, -0.3438,\n",
      "          0.3124, -0.4869,  0.4292, -0.7592, -0.1202, -0.5985, -0.1026, -0.0975,\n",
      "          0.7989, -0.4954,  0.3612,  0.0625]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "autoencoder = AutoEncoder()\n",
    "\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n",
    "loss_func = nn.MSELoss()\n",
    "for epoch in range(0,5):\n",
    "\n",
    "    for step,x in enumerate(train_img):\n",
    "        b_x = x.view(-1, 3*200*180)   \n",
    "        b_y = x.view(-1, 3*200*180)   \n",
    "        \n",
    "        encoded, decoded = autoencoder(b_x)\n",
    "        print(encoded)\n",
    "        np.savetxt(\"wei.csv\",encoded.detach().cpu().numpy()[0],delimiter=\",\")\n",
    "        \n",
    "        loss = loss_func(decoded, b_y)      \n",
    "        optimizer.zero_grad()               \n",
    "        loss.backward()\n",
    "        optimizer.step()                    \n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n",
    "        break\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
