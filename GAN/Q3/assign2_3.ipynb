{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ass2_3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "S2fWM3HvEBJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6173e92a-a077-4935-c672-154ec81159c4"
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler \n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h0hXBkYREIix",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_data():\n",
        "    root_dir = 'drive/My Drive/SAMPLE/faces94'\n",
        "    files = glob(f\"{root_dir}/**/**/*.jpg\")\n",
        "\n",
        "    c2i = {\n",
        "        \"female\": 0,\n",
        "        \"male\":1,\n",
        "        \"malestaff\": 2 \n",
        "    }\n",
        "    return files,c2i\n",
        "\n",
        "def display():\n",
        "    print(\"for batch\"+str(len(train_loader)))\n",
        "    print(\" -->> loss of the PartGen part and PartDicri part are :\" +  str(g_loss.item()) + \"  ,\" +  str(d_loss.item()))\n",
        "    \n",
        "def imgs_labels(c2i,files):\n",
        "  Tlabel = torch.tensor([c2i[x.split('/')[-3]] for x in files])\n",
        "  Timgs = torch.stack([TLoader(Image.open(x)) for x in files])\n",
        "  return Tlabel,Timgs\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Aat8chb5J8de",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 32\n",
        "LRate = 0.001\n",
        "IShape = (3, 200, 180)\n",
        "interval = 100\n",
        "bias1 = 0.5\n",
        "bias2 = 0.999\n",
        "hiddenUnits = 200\n",
        "\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "files,c2i=read_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lOqQXd_BJ_3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class PartDiscri(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PartDiscri, self).__init__()\n",
        "        #print(\"----\",int(np.prod(IShape)))\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(IShape)), 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        \n",
        "        img_flat = img.view(img.shape[0], -1)\n",
        "        allowedity = self.model(img_flat)\n",
        "\n",
        "        return allowedity\n",
        "      \n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(nn.Linear(3*200*180,2000 ),nn.Tanh(),nn.Linear(2000, 1000),nn.Tanh(),nn.Linear(1000, 200),nn.Tanh(),nn.Linear(200, 100),)\n",
        "        self.decoder = nn.Sequential(nn.Linear(100, 200),nn.Tanh(),nn.Linear(200, 1000),nn.Tanh(),nn.Linear(1000, 2000),nn.Tanh(),nn.Linear(2000, 3*200*180),nn.Sigmoid(),)\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded   \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DbPny9wCKDde",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOSS = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "PartGen = AutoEncoder()\n",
        "PartDiscri = PartDiscri()\n",
        "\n",
        "OGEN = torch.optim.Adam(PartGen.parameters(), lr=LRate, betas=(bias1, bias2))\n",
        "ODISCRI = torch.optim.Adam(PartDiscri.parameters(), lr=LRate, betas=(bias1, bias2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ayBoxjUOKHGM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Tensor = torch.FloatTensor\n",
        "\n",
        "TLoader = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5],[0.5])\n",
        "])\n",
        "\n",
        "Tlabel = torch.tensor([c2i[x.split('/')[-3]] for x in files])\n",
        "Timgs = torch.stack([TLoader(Image.open(x)) for x in files])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u4eC7Va2KO09",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_idx, test_idx = train_test_split(range(len(Timgs)), test_size=0.2, random_state=102)\n",
        "\n",
        "\n",
        "train_data = TensorDataset(Timgs[train_idx], Tlabel[train_idx])\n",
        "test_data = TensorDataset(Timgs[test_idx], Tlabel[test_idx])\n",
        "\n",
        "train_loader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=32)\n",
        "test_loader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=32)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i, (imgs,_) in enumerate(train_loader):\n",
        "        allowed = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "        NOTallowed = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "        OGEN.zero_grad()\n",
        "        s1=32\n",
        "        s2=108000\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (s1, s2))))\n",
        "        gen_imgs = PartGen(z)\n",
        "        g_loss = LOSS(PartDiscri(gen_imgs), allowed)\n",
        "\n",
        "        g_loss.backward()\n",
        "        OGEN.step()\n",
        "        ODISCRI.zero_grad()\n",
        "\n",
        "        # Measure PartDiscri's ability to classify real from generated samples\n",
        "        real_loss = LOSS(PartDiscri(real_imgs), allowed)\n",
        "        NOTallowed_loss = LOSS(PartDiscri(gen_imgs.detach()), NOTallowed)\n",
        "        d_loss = (real_loss + NOTallowed_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        ODISCRI.step()\n",
        "\n",
        "        display()\n",
        "\n",
        "        batches_done = epoch * len(train_loader) + i\n",
        "        if batches_done % interval == 0:\n",
        "            save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3E33kqDOLyX6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}